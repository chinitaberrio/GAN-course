{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "label_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fcn = torch.nn.Sequential(\n",
    "            # Fully Connected Layer 1\n",
    "            torch.nn.Linear(\n",
    "                in_features=noise_dim + label_dim,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 2\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 3\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 4\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 5\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 6\n",
    "            torch.nn.Linear(\n",
    "                in_features=240,\n",
    "                out_features=784,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, labels):\n",
    "        inputs = batch.view(batch.size(0), -1)\n",
    "        ret = torch.cat((inputs, labels), dim=1)\n",
    "        ret = self.fcn(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maxout Activation\n",
    "\n",
    "##### Source: https://github.com/pytorch/pytorch/issues/805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxout(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_pieces):\n",
    "\n",
    "        super(Maxout, self).__init__()\n",
    "\n",
    "        self.num_pieces = num_pieces\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x.shape = (batch_size? x 625)\n",
    "\n",
    "        assert x.shape[1] % self.num_pieces == 0  # 625 % 5 = 0\n",
    "\n",
    "        ret = x.view(\n",
    "            *x.shape[:1],  # batch_size\n",
    "            x.shape[1] // self.num_pieces,  # piece-wise linear\n",
    "            self.num_pieces,  # num_pieces\n",
    "            *x.shape[2:]  # remaining dimensions if any\n",
    "        )\n",
    "        \n",
    "        # ret.shape = (batch_size? x 125 x 5)\n",
    "\n",
    "        # https://pytorch.org/docs/stable/torch.html#torch.max        \n",
    "        ret, _ = ret.max(dim=2)\n",
    "\n",
    "        # ret.shape = (batch_size? x 125)\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fcn = torch.nn.Sequential(\n",
    "            # Fully Connected Layer 1\n",
    "            torch.nn.Linear(\n",
    "                in_features=784 + label_dim,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            Maxout(5),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 2\n",
    "            torch.nn.Linear(\n",
    "                in_features=48,\n",
    "                out_features=240,\n",
    "                bias=True\n",
    "            ),\n",
    "            Maxout(5),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            # Fully Connected Layer 3\n",
    "            torch.nn.Linear(\n",
    "                in_features=48,\n",
    "                out_features=1,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, labels):\n",
    "        ret = batch.view(batch.size(0), -1)\n",
    "        ret = torch.cat((ret, labels), dim=1)\n",
    "        ret = self.fcn(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac8077ad75f40b7bc56332673cb420e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/fashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d046afbe6c84e3bb3ca906d564139d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/fashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c051330baa0240e0972a95d20337c7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/fashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89650e285c034e0db5a7997e5362edad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/fashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/fashionMNIST/FashionMNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephany/miniconda3/envs/pytorch_env/lib/python3.6/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729004493/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class FlattenTransform:\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return inputs.view(inputs.shape[0], -1)\n",
    "\n",
    "\n",
    "data_train = torchvision.datasets.FashionMNIST(\n",
    "    './data/fashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        FlattenTransform()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "\n",
    "discriminator_optimizer = torch.optim.SGD(\n",
    "    discriminator.parameters(),\n",
    "    lr=0.003,\n",
    "    momentum=0.5\n",
    "#     dampening=0.0001\n",
    ")\n",
    "\n",
    "generator_optimizer = torch.optim.SGD(\n",
    "    generator.parameters(),\n",
    "    lr=0.001,\n",
    "    momentum=0.5\n",
    "#     dampening=0.0001\n",
    ")\n",
    "\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndiscriminator_scheduler = torch.optim.lr_scheduler.StepLR(\\n    optimizer=discriminator_optimizer,\\n    step_size=1,\\n    gamma=0.99,\\n    last_epoch=-1\\n)\\n\\ngenerator_scheduler = torch.optim.lr_scheduler.StepLR(\\n    optimizer=generator_optimizer,\\n    step_size=1,\\n    gamma=0.99,\\n    last_epoch=-1\\n)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "discriminator_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=discriminator_optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.99,\n",
    "    last_epoch=-1\n",
    ")\n",
    "\n",
    "generator_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=generator_optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.99,\n",
    "    last_epoch=-1\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decayLR(e):\n",
    "    if e < 200:\n",
    "        return 1\n",
    "    elif e < 400:\n",
    "        return 1 / (1 + e * 0.1)\n",
    "    elif e < 600:\n",
    "        return 1 / (1 + e * 0.001)\n",
    "    elif e < 800:\n",
    "        return 1 / (1 + e * 0.00001)\n",
    "    elif e < 1000:\n",
    "        return 1 / (1 + e * 0.0000001)\n",
    "    else:\n",
    "        return 1 / (1 + e * 0.000000001)\n",
    "\n",
    "\n",
    "discriminator_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    discriminator_optimizer,\n",
    "    decayLR\n",
    ")\n",
    "\n",
    "generator_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    generator_optimizer,\n",
    "    decayLR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeGAN(tgt_pth, images, labels, epoch):\n",
    "\n",
    "    categories = [\n",
    "        'T-shirt/top',\n",
    "        'Trouser',\n",
    "        'Pullover',\n",
    "        'Dress',\n",
    "        'Coat',\n",
    "        'Sandal',\n",
    "        'Shirt',\n",
    "        'Sneaker',\n",
    "        'Bag',\n",
    "        'Ankle boot'\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 18))\n",
    "    \n",
    "    fig.suptitle('Epoch {}'.format(str(epoch).zfill(4)))\n",
    "\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            cell.imshow(\n",
    "                images[row * 5 + col],\n",
    "                cmap='gray'\n",
    "            )\n",
    "            \n",
    "            cell.set_title('{}'.format(\n",
    "                categories[torch.argmax(labels[row * 5 + col])]\n",
    "            ))\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(epoch).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeOneHot(labels):\n",
    "    ret = torch.FloatTensor(labels.shape[0], label_dim)\n",
    "    ret.zero_()\n",
    "    ret.scatter_(dim=1, index=labels.view(-1, 1), value=1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = torch.ones(BATCH_SIZE, 1).to(device)\n",
    "fake_labels = torch.zeros(BATCH_SIZE, 1).to(device)\n",
    "\n",
    "test_z = (2 * torch.randn(10, noise_dim) - 1).to(device)\n",
    "test_y = encodeOneHot(torch.tensor(np.arange(0, 10))).to(device)\n",
    "\n",
    "num_epochs = 2048\n",
    "num_steps = len(train_loader) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "visuals_dir = 'visuals-section-3-lecture-2-fashion-mnist-exercise-b'\n",
    "\n",
    "if not os.path.exists(visuals_dir):\n",
    "    os.mkdir(visuals_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephany/miniconda3/envs/pytorch_env/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:0, G:1.014, D:0.020, G_LR:[0.001], D_LR:[0.003]\n",
      "e:10, G:6.251, D:0.002, G_LR:[0.001], D_LR:[0.003]\n",
      "e:20, G:7.132, D:0.001, G_LR:[3.289473684210526e-05], D_LR:[9.868421052631579e-05]\n",
      "e:30, G:7.626, D:0.001, G_LR:[0.0006973500697350071], D_LR:[0.002092050209205021]\n",
      "e:40, G:8.551, D:0.001, G_LR:[0.0006353240152477764], D_LR:[0.0019059720457433292]\n",
      "e:50, G:8.166, D:0.000, G_LR:[0.000992910618186151], D_LR:[0.002978731854558453]\n",
      "e:60, G:2.716, D:0.006, G_LR:[0.0009999146072925374], D_LR:[0.002999743821877612]\n",
      "e:70, G:2.712, D:0.008, G_LR:[0.0009999006098793779], D_LR:[0.002999701829638134]\n",
      "e:80, G:3.267, D:0.003, G_LR:[0.000999998866001286], D_LR:[0.0029999965980038582]\n"
     ]
    }
   ],
   "source": [
    "d_loss_ls = []\n",
    "g_loss_ls = []\n",
    "d_lr_ls = []\n",
    "g_lr_ls = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Loss Log\n",
    "    d_counter = 0\n",
    "    g_counter = 0\n",
    "    d_loss = 0\n",
    "    g_loss = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        if i == num_steps:\n",
    "            break\n",
    "\n",
    "        # Train Discriminator\n",
    "        for _ in range(4):\n",
    "        \n",
    "            real_images = images.to(device)\n",
    "            real_conditions = encodeOneHot(labels).to(device)\n",
    "\n",
    "            fake_conditions = encodeOneHot(torch.randint(0, 10, (BATCH_SIZE,))).to(device)\n",
    "\n",
    "            fake_images = generator(\n",
    "                (2 * torch.randn(BATCH_SIZE, noise_dim) - 1).to(device),\n",
    "                fake_conditions\n",
    "            )\n",
    "\n",
    "            discriminator_optimizer.zero_grad()\n",
    "\n",
    "            real_outputs = discriminator(real_images, real_conditions)\n",
    "            fake_outputs = discriminator(fake_images, fake_conditions)\n",
    "\n",
    "            d_x = criterion(real_outputs, real_labels)\n",
    "            d_g_z = criterion(fake_outputs, fake_labels)\n",
    "\n",
    "            d_x.backward()\n",
    "            d_g_z.backward()\n",
    "\n",
    "            discriminator_optimizer.step()\n",
    "            \n",
    "            # Loss Log\n",
    "            d_counter += 1\n",
    "            d_loss = d_x.item() + d_g_z.item()\n",
    "\n",
    "\n",
    "        # Train Generator\n",
    "        z = (2 * torch.randn(BATCH_SIZE, noise_dim) - 1).to(device)\n",
    "        y = encodeOneHot(torch.randint(0, 10, (BATCH_SIZE,))).to(device)\n",
    "\n",
    "        generator.zero_grad()\n",
    "\n",
    "        outputs = discriminator(generator(z, y), y)\n",
    "\n",
    "        loss = criterion(outputs, real_labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "        # LR Decay\n",
    "        discriminator_scheduler.step()\n",
    "        generator_scheduler.step()\n",
    "        \n",
    "        # Loss Log\n",
    "        g_counter += 1\n",
    "        g_loss += loss.item()\n",
    "\n",
    "    # Loss Log\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            'e:{}, G:{:.3f}, D:{:.3f}, G_LR:{}, D_LR:{}'.format(\n",
    "                epoch,\n",
    "                g_loss / g_counter,\n",
    "                d_loss / d_counter,\n",
    "                generator_scheduler.get_lr(),\n",
    "                discriminator_scheduler.get_lr()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Loss Log for Plot\n",
    "    g_loss_ls.append(g_loss / g_counter)\n",
    "    d_loss_ls.append(d_loss / d_counter)\n",
    "    \n",
    "    # Learning Rate Decay Log\n",
    "    g_lr_ls.append(generator_scheduler.get_lr())\n",
    "    d_lr_ls.append(discriminator_scheduler.get_lr())\n",
    "\n",
    "\n",
    "    # Visualize Results\n",
    "    if epoch % 5 == 0:\n",
    "\n",
    "        generated = generator(test_z, test_y).detach().cpu().view(-1, 28, 28)\n",
    "\n",
    "        visualizeGAN(visuals_dir, generated, test_y, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "generated = generator(test_z, test_y).detach().cpu().view(-1, 28, 28)\n",
    "\n",
    "visualizeGAN(visuals_dir, generated, test_y, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "plt.plot(d_loss_ls, label='D Loss')\n",
    "plt.plot(g_loss_ls, label='G Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "plt.plot(d_lr_ls, label='D LR')\n",
    "plt.plot(g_lr_ls, label='G LR')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Collaboratory\n",
    "\n",
    "Notebook: https://colab.research.google.com/drive/17A_Ecl2sZdXra_YSnt7F-F4Z8vCa2U2J"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
